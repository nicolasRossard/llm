# ğŸ§  RAG with Hexagonal Architecture (FastAPI + LLM + Vector DB)

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline using:

- **FastAPI** for the API layer
- **Ollama or OpenAI or litellm** as the LLM providers
- **Qdrant** for vector similarity search
- A **Hexagonal Architecture** (ports & adapters) with clear separation of components following **Domain-Driven Design** principles
- **Domain-Driven Design (DDD)** to model complex business domains and maintain a ubiquitous language
- Clear boundaries between application, domain, and infrastructure layers to ensure modularity and testability

---

## ğŸ“ Project Structure

```
backend
â”œâ”€â”€ config.py                  # Global configuration settings for the application
â”œâ”€â”€ main.py                    # Application entry point - initializes FastAPI and dependencies
â”œâ”€â”€ src
â”‚   â””â”€â”€ components
â”‚       â””â”€â”€ chatbot            # RAG Chatbot component following hexagonal architecture
â”‚           â”œâ”€â”€ application    # Application layer
â”‚           â”‚   â”œâ”€â”€ ports      # Interfaces defining how to interact with the application core
â”‚           â”‚   â”‚   â”œâ”€â”€ driven  # Interfaces that the application uses to communicate outward
â”‚           â”‚   â”‚   â”‚          # (e.g., VectorRepository, LLMProvider interfaces)
â”‚           â”‚   â”‚   â””â”€â”€ driving # Interfaces that allow external systems to use the application
â”‚           â”‚   â”‚              # (e.g., ChatbotPort interface)
â”‚           â”‚   â”œâ”€â”€ services   # Implementation of application services that orchestrate use cases
â”‚           â”‚   â”‚              # (e.g., ChatCompletionService)
â”‚           â”‚   â””â”€â”€ use_case_handlers  # Business logic specific to each use case which are implemented with driving port interfaces
â”‚           â”œâ”€â”€ domain         # Domain layer - core business rules and concepts
â”‚           â”‚   â”œâ”€â”€ entities   # Business objects with identity and lifecycle
â”‚           â”‚   â”‚              # (e.g., Message, Conversation, Document)
â”‚           â”‚   â”œâ”€â”€ repositories # Repository interfaces for domain objects
â”‚           â”‚   â”‚              # (e.g., DocumentRepository, ConversationRepository)
â”‚           â”‚   â”œâ”€â”€ services   # Domain services that operate on multiple entities
â”‚           â”‚   â”‚              # (e.g., VectorEmbeddingService)
â”‚           â”‚   â””â”€â”€ value_objects # Immutable objects without identity
â”‚           â”‚                  # (e.g., Embedding, Query, DocumentChunk)
â”‚           â””â”€â”€ infrastructure # Infrastructure layer - technical details and implementations
â”‚               â”œâ”€â”€ adapters   # Connect the application to external systems
â”‚               â”‚   â”œâ”€â”€ driven # Implementations of ports the application uses
â”‚               â”‚   â”‚          # (e.g., OpenAIAdapter, QdrantAdapter)
â”‚               â”‚   â”œâ”€â”€ driving # Implementations of ports to drive the application
â”‚               â”‚              # (e.g., ChatbotRESTAdapter)
â”‚               â”œâ”€â”€ api        # API definition and routing
â”‚               â”‚   â””â”€â”€ v1     # API version 1
â”‚               â”‚       â”œâ”€â”€ rag_routes.py # FastAPI route definitions for rag
â”‚               â”‚       â”œâ”€â”€ dto.py           # Data Transfer Objects for API requests/responses
â”‚               â”œâ”€â”€ config     # Infrastructure-specific configuration
â”‚               â”‚              # (e.g., QdrantConfig, LLMConfig)
â”‚               â”œâ”€â”€ di         # Dependency Injection configuration
â”‚               â””â”€â”€ repositories # Implementation of repository interfaces
â”‚                   â””â”€â”€ qdrant_vector_repository.py # Concrete implementation for Qdrant and persistence storage
â””â”€â”€ uvicorn_debug.py          # Script for running the app in debug mode with uvicorn

```

---

## âš™ï¸ Key Concepts
- **Hexagonal Architecture**  
  Ports define *what the system needs*; adapters define *how it's fulfilled*.
  
- **RAG Process**
  1. A question is submitted to the API
  2. Vector search retrieves relevant documents
  3. LLM generates an answer based on those documents
  4. (Optionally) The interaction is logged in a database (WIP)

- **Swappable Adapters**
  - You can switch between OpenAI and Ollama LLM clients (WIP)
  - You can replace Qdrant with another vector store easily

---

## ğŸ Getting Started

1. Clone the repository
2. Install packages

```bash
docker compose up
make run
````

---

## ğŸ§ª Testing Without Real Qdrant

A fake implementation of `QdrantAdapter` is provided for local development/testing without connecting to a real vector DB.

---

## ğŸ“Œ License

MIT â€“ feel free to use and adapt.
